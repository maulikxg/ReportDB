package reader

import (
	. "datastore/containers"
	. "datastore/storage"
	. "datastore/utils"
	"errors"
	"fmt"
	"go.uber.org/zap"
	"log"
	"sync"
	"time"
)

func reader(queryReceiveChannel <-chan Query, queryResultChannel chan<- Result, storagePool *StoragePool, readersWaitGroup *sync.WaitGroup) {

	defer readersWaitGroup.Done()

	for query := range queryReceiveChannel {

		startTime := time.Now()

		result, err := queryHistogram(query.From, query.To, query.CounterId, query.ObjectIds, storagePool)

		if err != nil {

			log.Printf("Error querying datastore: %s" + err.Error())

		}

		queryResultChannel <- Result{

			QueryId: query.QueryId,

			Data: result,
		}

		dataPoints := 0

		for _, resultPoint := range result {
			dataPoints += len(resultPoint)
		}

		fmt.Println("Total Data Points: ", dataPoints, "In:", time.Since(startTime))

	}

	// channel closed, shutdown is called

	Logger.Info("Reader exiting.")

}

func queryHistogram(from uint32, to uint32, counterId uint16, objects []uint32, storagePool *StoragePool) (map[uint32][]DataPoint, error) {

	finalData := map[uint32][]DataPoint{}

	for date := from - (from % 86400); date <= to; date += 86400 {

		dateObject := UnixToDate(date)

		storageKey := StoragePoolKey{

			Date: dateObject,

			CounterId: counterId,
		}

		storageEngine, err := storagePool.GetStorage(storageKey, false)

		if err != nil {

			if errors.Is(err, ErrStorageDoesNotExist) {

				Logger.Info("Storage not present for date:"+dateObject.Format(), zap.Uint16("counterID:", counterId))

				continue

			}

			return nil, err

		}

		readSingleDay(dateObject, storageEngine, counterId, objects, finalData, from, to)

		if storageKey.Date.Day != time.Now().Day() {

			// Close storage for days other than current day.
			// current day's storage is constantly used by writer hence no need to close it.

			storagePool.CloseStorage(storageKey)
		}

	}

	return finalData, nil

}

// readSingleDay Note: readFullDate function changes the state of the finalData; hence if run in parallel, proper synchronization is needed.
func readSingleDay(date Date, storageEngine *Storage, counterId uint16, objects []uint32, finalData map[uint32][]DataPoint, from uint32, to uint32) {

	for _, objectId := range objects {

		data, err := storageEngine.Get(objectId)

		if err != nil {

			Logger.Info("Error getting dataPoint ", zap.Uint32("ObjectId", objectId), zap.String("Date", date.Format()))
			continue

		}

		dataPoints, err := DeserializeBatch(data, CounterConfig[counterId][DataType].(string))

		if err != nil {

			Logger.Info("Error deserializing dataPoint for objectId: ", zap.Uint32("ObjectId", objectId), zap.String("Date", date.Format()), zap.Error(err))

			continue

		}

		// Append dataPoints if they lie between from and to

		for _, dataPoint := range dataPoints {

			if dataPoint.Timestamp >= from && dataPoint.Timestamp <= to {

				finalData[objectId] = append(finalData[objectId], dataPoint)

			}

		}

	}
} this is reader and tihis is storage engine get implemtation
func (storage *Storage) Get(key uint32) ([]byte, error) {

	file, err := storage.openFilesPool.GetFileMapping(key%storage.partitionCount, storage.storagePath)

	if err != nil {

		return nil, err

	}

	index, err := storage.indexPool.Get(key%storage.partitionCount, storage.storagePath)

	if err != nil {

		return nil, err

	}

	blocks := index.GetIndexObjectBlocks(key)

	if blocks == nil {

		return nil, ErrObjectDoesNotExist

	}

	data := file.ReadBlocks(blocks, storage.blockSize)

	return data, nil

}

take this reader as the inspiration so i want u do the some kind of same like this from the get in the reader u get the blocks relate to that object id from the reading the index in the storage get the blocks and in the reader that blocks can used cehck if the from the header information the data we what to read is in this block or go to next block using that nextblockoffset setore in the blaocks so and if any blocks match the get the all the timestamps for that and deseralize all the datapoints so i want some kind of this implemtation that works and can read my data properly implemt that in out system reader





--------------------------------------------

so i wnat that u make the serialization more proper and based on the datatypes of the i have declared in the @models.go chenage for the blocks header also and here tak case that deviceid is objectid . also i wnat that this structure should be wokring with the int , float and string data so serialization should that best that works for all this and all so make the block header is being writen proper so list the problems for now
----------------------------------------

first thing that i want to change is that the block header and new blockheader structure will be the type BlockHeader struct {
                                                                                                         DeviceID uint32      // 4 bytes - matches ObjectID type
                                                                                                         StartTimestamp uint32 // 4 bytes - matches Timestamp type
                                                                                                         EndTimestamp uint32   // 4 bytes - matches Timestamp type
                                                                                                         NextBlockOffset int64 // 8 bytes
                                                                                                         RecordCount uint32    // 4 bytes
                                                                                                         DataType byte        // 1 byte - indicates value type
                                                                                                     }
which is matches our models.go declarations.now i do thinks the way we are writing the data in the serialize way is go with this now like for the int or the float data the length is not needed but in the string data be also add the length of the string also so no  need to change the serialize the data. so now that in the block the new way the data will be the written in the blocks and i wnat u to remove the date from the index also beacuse it is not needed

-----------------------------------------
-------------------------------------------

 {
        "device_id": 2,
        "block_offset": 12288,
        "current_offset": 0
    }


 ----------

 there is more issue in this when i run the code and stop the @main.go in the @index.json the lockoffset was the 12288 but if i start the main.go again it now shows the 4096 so why that happess?


 so if for the any device the for the first the the size will the 1024 and nect time the size will increase because



 but in this case First write for Device 1:
 Function returns offset 0 (baseOffset)
 Sets nextOffset[1] = 4096 (for next time)
 Data is written at position 0
 Second write for Device 1:
 Function returns offset 4096 (from nextOffset[1])
 Sets nextOffset[1] = 8192 (for next time)
 Data is written at position 4096
 Third write for Device 1:
 Function returns offset 8192 (from nextOffset[1])
 Sets nextOffset[1] = 12288 (for next time)
 Data is written at position 8192 if the i have the new entey why use the new block when the old block will hav the space



 ---------------------------------------------__________-
 ------------------------------------------------
 so in the blockstorage my strategie was that every device will have the fix sized block and if that block is filled will assign the anotehr and chain it willl the previous and in the hrader the metadata is store to sue the easy data retrival so that was the main plan and desing so it is good for this network mitoring time series data or not ,and why in this mmap setup in the storageengine i see the blocksie i defined is not assigned to devices or the object why that ? i have seen the  {
         "device_id": 2,
         "block_offset": 12288,
         "current_offset": 0
     } this so why this when i declare the size in @config.json of the block is 1024 so explain all this and how this all are being the happning 