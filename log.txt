2025/04/23 14:08:07 Found 1 data blocks for ObjectID 1
2025/04/23 14:08:07 Adding data point: timestamp=1745397483, value=1e-323
2025/04/23 14:08:07 Found total 1 data points for ObjectID 1
2025/04/23 14:08:07 Aggregated 1 points to 1 points using avg
2025/04/23 14:08:07 Processing ObjectID: 2
2025/04/23 14:08:07 Checking path: /home/maulikpuri/Desktop/v1/storageData/2025/04/23/counter_1
2025/04/23 14:08:07 Found 1 data blocks for ObjectID 2
2025/04/23 14:08:07 Found total 0 data points for ObjectID 2
2025/04/23 14:08:07 Sending response for QueryID 2 with 2 objects
2025/04/23 14:08:07 Preparing to send response for QueryID: 2 with 2 objects
2025/04/23 14:08:07 Successfully sent response for QueryID: 2
2025/04/23 14:08:09 Polled CPU usage: 2.70%
2025/04/23 14:08:09 Sent metric through ZMQ: counterID=1 , DeviceID=1, CPU=2.70%
2025/04/23 14:08:09 Received metric: {1 1 2.7 1745397489}
2025/04/23 14:08:09 Received and queued metric: DeviceID=1, CounterID=1, Value=2.7
2025/04/23 14:08:09 Writer received batch for ObjectId: 1, CounterId: 1, Count: 1
2025/04/23 14:08:09 {1 1 2.7 1745397489}
2025/04/23 14:08:09 Successfully stored metric for ObjectId: 1, Timestamp: 1745397489, Value: 2.7
2025/04/23 14:08:09 Writer finished processing batch for ObjectId: 1
2025/04/23 14:08:15 Polled CPU usage: 4.10%
2025/04/23 14:08:15 Sent metric through ZMQ: counterID=1 , DeviceID=1, CPU=4.10%
2025/04/23 14:08:15 Received metric: {1 1 4.1 1745397495}
2025/04/23 14:08:15 Received and queued metric: DeviceID=1, CounterID=1, Value=4.1
2025/04/23 14:08:17 Writer received batch for ObjectId: 1, CounterId: 1, Count: 1
2025/04/23 14:08:17 {1 1 4.1 1745397495}
2025/04/23 14:08:17 Successfully stored metric for ObjectId: 1, Timestamp: 1745397495, Value: 4.1
2025/04/23 14:08:17 Writer finished processing batch for ObjectId: 1
2025/04/23 14:08:21 Polled CPU usage: 15.70%
2025/04/23 14:08:21 Sent metric through ZMQ: counterID=1 , DeviceID=1, CPU=15.70%
2025/04/23 14:08:21 Received metric: {1 1 15.7 1745397501}
2025/04/23 14:08:21 Received and queued metric: DeviceID=1, CounterID=1, Value=15.7
2025/04/23 14:08:21 Writer received batch for ObjectId: 1, CounterId: 1, Count: 1
2025/04/23 14:08:21 {1 1 15.7 1745397501}
2025/04/23 14:08:21 Successfully stored metric for ObjectId: 1, Timestamp: 1745397501, Value: 15.7
2025/04/23 14:08:21 Writer finished processing batch for ObjectId: 1


it is till issue that when i query the data from to to timestapmp not proper time stamps are showing me and i check i found that aggrgation is giving the wrong can u fix this and tell mw what is the issue why the not actual data points are not being the display test this and give me the working this and also log the all the data points at the reading so i can verify and make it fully working


u run all this and test and check theworking or not i wnat u to run theso data being write @main.go and at the same time run the @client for the query to check the all the data points of the last 50 seconds and i wnat to check the logs that data written is getteed in the query result so check the rawdata written and for the query for that time range is same and make it workable  and u run this files and test this updates u do utils its working do and so i can see the data being write is read live make this implemet




package reader

import (
	. "datastore/containers"
	. "datastore/storage"
	. "datastore/utils"
	"errors"
	"fmt"
	"go.uber.org/zap"
	"log"
	"sync"
	"time"
)

func reader(queryReceiveChannel <-chan Query, queryResultChannel chan<- Result, storagePool *StoragePool, readersWaitGroup *sync.WaitGroup) {

	defer readersWaitGroup.Done()

	for query := range queryReceiveChannel {

		startTime := time.Now()

		result, err := queryHistogram(query.From, query.To, query.CounterId, query.ObjectIds, storagePool)

		if err != nil {

			log.Printf("Error querying datastore: %s" + err.Error())

		}

		queryResultChannel <- Result{

			QueryId: query.QueryId,

			Data: result,
		}

		dataPoints := 0

		for _, resultPoint := range result {
			dataPoints += len(resultPoint)
		}

		fmt.Println("Total Data Points: ", dataPoints, "In:", time.Since(startTime))

	}

	// channel closed, shutdown is called

	Logger.Info("Reader exiting.")

}

func queryHistogram(from uint32, to uint32, counterId uint16, objects []uint32, storagePool *StoragePool) (map[uint32][]DataPoint, error) {

	finalData := map[uint32][]DataPoint{}

	for date := from - (from % 86400); date <= to; date += 86400 {

		dateObject := UnixToDate(date)

		storageKey := StoragePoolKey{

			Date: dateObject,

			CounterId: counterId,
		}

		storageEngine, err := storagePool.GetStorage(storageKey, false)

		if err != nil {

			if errors.Is(err, ErrStorageDoesNotExist) {

				Logger.Info("Storage not present for date:"+dateObject.Format(), zap.Uint16("counterID:", counterId))

				continue

			}

			return nil, err

		}

		readSingleDay(dateObject, storageEngine, counterId, objects, finalData, from, to)

		if storageKey.Date.Day != time.Now().Day() {

			// Close storage for days other than current day.
			// current day's storage is constantly used by writer hence no need to close it.

			storagePool.CloseStorage(storageKey)
		}

	}

	return finalData, nil

}

// readSingleDay Note: readFullDate function changes the state of the finalData; hence if run in parallel, proper synchronization is needed.
func readSingleDay(date Date, storageEngine *Storage, counterId uint16, objects []uint32, finalData map[uint32][]DataPoint, from uint32, to uint32) {

	for _, objectId := range objects {

		data, err := storageEngine.Get(objectId)

		if err != nil {

			Logger.Info("Error getting dataPoint ", zap.Uint32("ObjectId", objectId), zap.String("Date", date.Format()))
			continue

		}

		dataPoints, err := DeserializeBatch(data, CounterConfig[counterId][DataType].(string))

		if err != nil {

			Logger.Info("Error deserializing dataPoint for objectId: ", zap.Uint32("ObjectId", objectId), zap.String("Date", date.Format()), zap.Error(err))

			continue

		}

		// Append dataPoints if they lie between from and to

		for _, dataPoint := range dataPoints {

			if dataPoint.Timestamp >= from && dataPoint.Timestamp <= to {

				finalData[objectId] = append(finalData[objectId], dataPoint)

			}

		}

	}
} this is reader and tihis is storage engine get implemtation
func (storage *Storage) Get(key uint32) ([]byte, error) {

	file, err := storage.openFilesPool.GetFileMapping(key%storage.partitionCount, storage.storagePath)

	if err != nil {

		return nil, err

	}

	index, err := storage.indexPool.Get(key%storage.partitionCount, storage.storagePath)

	if err != nil {

		return nil, err

	}

	blocks := index.GetIndexObjectBlocks(key)

	if blocks == nil {

		return nil, ErrObjectDoesNotExist

	}

	data := file.ReadBlocks(blocks, storage.blockSize)

	return data, nil

}

take this reader as the inspiration so i want u do the some kind of same like this from the get in the reader u get the blocks relate to that object id from the reading the index in the storage get the blocks and in the reader that blocks can used cehck if the from the header information the data we what to read is in this block or go to next block using that nextblockoffset setore in the blaocks so and if any blocks match the get the all the timestamps for that and deseralize all the datapoints so i want some kind of this implemtation that works and can read my data properly implemt that in out system reader and for the deserialization check the how the serialization done in thw writer and fix the issue if any realted to read the index file and anything check all the aspects and make the read and write concurrent

so now implemt this and auto run and test the changes and if errors come solve that errors but dont change the project structure at all